{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import torch\n",
    "import nibabel as nib\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from skimage.exposure import equalize_hist\n",
    "from einops.einops import rearrange\n",
    "from ipywidgets import interact, IntSlider\n",
    "from scipy.ndimage import generate_binary_structure, binary_opening, label\n",
    "from skimage.measure import regionprops\n",
    "from glob import glob\n",
    "from scipy.ndimage import generate_binary_structure, binary_opening\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import erosion, disk, convex_hull_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función auxiliar para mostrar imágenes (se adapta a arreglos 2D o con canal único)\n",
    "def display_debug(img, title=\"Imagen\"):\n",
    "    # Si es un arreglo enmascarado, se convierte a arreglo normal rellenando con 0\n",
    "    if isinstance(img, np.ma.MaskedArray):\n",
    "        img = img.filled(0)\n",
    "    # Si la imagen tiene 3 dimensiones y el primer eje es de tamaño 1, mostramos ese canal\n",
    "    if img.ndim == 3:\n",
    "        if img.shape[0] == 1:\n",
    "            img_to_show = img[0]\n",
    "        else:\n",
    "            img_to_show = img[0]  # O se podría elegir la del medio, según convenga\n",
    "    else:\n",
    "        img_to_show = img\n",
    "    plt.figure()\n",
    "    plt.imshow(img_to_show, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_np(array, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        np.save(f, array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocessor_4d(nifti, clip_value, debug=True):\n",
    "    \"\"\"\n",
    "    Preprocesa un array 4D (t, z, x, y) aplicando:\n",
    "      1. Clip: recortar los valores a [0, clip_value].\n",
    "      2. Ecualización del histograma para cada imagen 2D (para cada t y z).\n",
    "      3. Sustracción del mínimo global.\n",
    "      4. Desplazar la distribución (restar 0.5) sin modificar los ceros.\n",
    "\n",
    "    Además, en cada paso se verifica que no aparezcan valores extraños (NaN o Inf).\n",
    "    Si se detectan, se identifican las slices problemáticas en la dimensión z y se eliminan\n",
    "    de la imagen (en todos los frames t). Si tras la eliminación aún se encuentran problemas,\n",
    "    se retorna la imagen original.\n",
    "\n",
    "    Parámetros:\n",
    "      nifti: np.ndarray\n",
    "          Array 4D de entrada con dimensiones (t, z, x, y).\n",
    "      clip_value: float\n",
    "          Valor máximo para recortar la imagen.\n",
    "      debug: bool\n",
    "          Si es True, muestra imágenes intermedias (se muestra la imagen del primer frame y slice, t=0, z=0)\n",
    "          y mensajes de aviso en caso de detectar valores extraños.\n",
    "\n",
    "    Retorna:\n",
    "      mdata: np.ndarray\n",
    "          Array 4D preprocesado (con las slices z problemáticas eliminadas) o, en caso de no poder limpiar,\n",
    "          la imagen original.\n",
    "      z_map_local: list\n",
    "          Lista con los índices de las slices z que se mantuvieron tras la limpieza.\n",
    "    \"\"\"\n",
    "\n",
    "    # Función interna para verificar la validez del array\n",
    "    def is_valid(arr):\n",
    "        return np.isfinite(arr).all()\n",
    "\n",
    "    def remove_problematic_z_slices(arr, debug, z_map):\n",
    "        \"\"\"\n",
    "        Revisa cada slice z (para todos los t) y elimina aquellas en las que se encuentre algún valor\n",
    "        extraño (NaN o Inf). Se espera que arr tenga forma (t, z, x, y).\n",
    "        \"\"\"\n",
    "        t_dim, z_dim, _, _ = arr.shape\n",
    "        good_z = []      # índices de slices sin problemas\n",
    "        removed_z = []   # índices de slices a eliminar\n",
    "\n",
    "        for z in range(z_dim):\n",
    "            # Se evalúa la slice z en todos los t\n",
    "            slice_z = arr[:, z, :, :]\n",
    "            if np.isfinite(slice_z).all():\n",
    "                good_z.append(z)\n",
    "            else:\n",
    "                removed_z.append(z)\n",
    "\n",
    "        if debug and removed_z:\n",
    "            print(f\"Se detectaron valores extraños en las slices z: {removed_z}. Se eliminarán.\")\n",
    "\n",
    "        if len(good_z) == 0:\n",
    "            if debug:\n",
    "                print(\"Todas las slices z contienen valores extraños. No se puede limpiar.\")\n",
    "            return arr, z_map\n",
    "        \n",
    "        clean_arr = arr[:, good_z, :, :]\n",
    "        new_z_map = [z_map[z] for z in good_z]\n",
    "\n",
    "        # Se elimina la dimensión z problemática para TODOS los frames t\n",
    "        return clean_arr, new_z_map\n",
    "\n",
    "    t_dim, z_dim, x_dim, y_dim = nifti.shape\n",
    "    z_map_local = list(range(z_dim))\n",
    "\n",
    "    # --- Paso 1: Clip ---\n",
    "    nifti_clipped = np.clip(nifti, 0, clip_value)\n",
    "    if not is_valid(nifti_clipped):\n",
    "        nifti_clipped, z_map_local = remove_problematic_z_slices(nifti_clipped, debug, z_map_local)\n",
    "\n",
    "    if debug:\n",
    "        display_debug(nifti_clipped[0, 0], \"Después del clip (t=0, z=0)\")\n",
    "\n",
    "    # --- Paso 2: Ecualización del histograma para cada imagen 2D ---\n",
    "    t_dim, z_dim, height, width = nifti_clipped.shape\n",
    "    nifti_eq = np.empty((t_dim, z_dim, height, width), dtype=np.float32)\n",
    "    for t in range(t_dim):\n",
    "        for z in range(z_dim):\n",
    "            # Se ecualiza cada imagen 2D individualmente.\n",
    "            nifti_eq[t, z] = equalize_hist(\n",
    "                nifti_clipped[t, z],\n",
    "                nbins=20000,\n",
    "                mask=(nifti_clipped[t, z] > 0)\n",
    "            )\n",
    "    if not is_valid(nifti_eq):\n",
    "        nifti_eq, z_map_local = remove_problematic_z_slices(nifti_eq, debug, z_map_local)\n",
    "        if not is_valid(nifti_eq):\n",
    "            if debug:\n",
    "                print(\"Aún se detectan valores extraños después de ecualizar el histograma y eliminación de slices. Se retorna la imagen original.\")\n",
    "            return nifti\n",
    "    if debug:\n",
    "        display_debug(nifti_eq[0, 0], \"Después de ecualizar histograma (t=0, z=0)\")\n",
    "\n",
    "    # --- Paso 3: Sustracción del mínimo global ---\n",
    "    global_min = np.min(nifti_eq)\n",
    "    nifti_eq = nifti_eq - global_min\n",
    "    if not is_valid(nifti_eq):\n",
    "        nifti_eq = remove_problematic_z_slices(nifti_eq, debug)\n",
    "        if not is_valid(nifti_eq):\n",
    "            if debug:\n",
    "                print(\"Aún se detectan valores extraños después de restar el mínimo y eliminación de slices. Se retorna la imagen original.\")\n",
    "            return nifti\n",
    "    if debug:\n",
    "        display_debug(nifti_eq[0, 0], \"Después de restar el mínimo (t=0, z=0)\")\n",
    "\n",
    "    # --- Paso 4: Desplazar la distribución sin modificar los ceros (restar 0.5) ---\n",
    "    mask = (nifti_eq > 0)\n",
    "    # Se crea un array enmascarado; los ceros se mantienen inalterados.\n",
    "    mdata = np.ma.masked_array(nifti_eq, mask=~mask)\n",
    "    mdata = mdata - 0.5\n",
    "    mdata.mask = np.ma.nomask  # Se \"desenmascara\" para continuar el procesamiento\n",
    "    if not is_valid(mdata):\n",
    "        mdata = remove_problematic_z_slices(mdata, debug)\n",
    "        if not is_valid(mdata):\n",
    "            if debug:\n",
    "                print(\"Aún se detectan valores extraños después de desplazar la distribución y eliminación de slices. Se retorna la imagen original.\")\n",
    "            return nifti\n",
    "    if debug:\n",
    "        display_debug(mdata[0, 0], \"Después de desplazar la distribución (t=0, z=0)\")\n",
    "\n",
    "    return mdata, z_map_local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_threshold_mask(data_2D, umbral=0.3, debug=False):\n",
    "    \"\"\"\n",
    "    Genera una máscara de cerebro a partir del frame t=0 usando un umbral simple.\n",
    "    - data: array (H, W)\n",
    "    - umbral: valor de umbral para separar hueso de tejido (dependerá de tus datos)\n",
    "    \n",
    "    Devuelve:\n",
    "      - mask: array binario (H, W) con True en las regiones (posible cerebro).\n",
    "    \"\"\"\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Seleccionado frame t=0.\")\n",
    "        print(\"Estadísticas de t0_image: min =\", data_2D.min(), \", max =\", data_2D.max())\n",
    "        plt.figure()\n",
    "        plt.title(\"Frame t=0 original\")\n",
    "        plt.imshow(data_2D, cmap='gray')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    \n",
    "    # 2. Aplicar el umbral: creamos una máscara con True donde el valor < umbral. \n",
    "    # False corresponde a la primera aproximación del cráneo.\n",
    "    mask = data_2D < umbral\n",
    "    if debug:\n",
    "        print(f\"Aplicado threshold: valores < {umbral} se vuelven True.\")\n",
    "        print(\"Valores únicos en la máscara tras threshold:\", np.unique(mask))\n",
    "        plt.figure()\n",
    "        plt.title(\"Máscara después del threshold\")\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    \n",
    "    # 3. Limpieza morfológica para eliminar ruido y rellenar huecos.\n",
    "    # 3.1. Generamos la estructura 2D para la operación morfológica.\n",
    "    struct_2d = generate_binary_structure(2, 1)\n",
    "    \n",
    "    # 3.2. Aplicamos binary opening (elimina pequeños objetos aislados).\n",
    "    mask_opened = binary_opening(mask, structure=struct_2d, iterations=5)\n",
    "    if debug:\n",
    "        print(\"Después de binary_opening:\")\n",
    "        print(\"Valores únicos:\", np.unique(mask_opened))\n",
    "        plt.figure()\n",
    "        plt.title(\"Máscara tras binary_opening\")\n",
    "        plt.imshow(mask_opened, cmap='gray')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    \n",
    "    # 3.3. Se identifican posibles calcificaciones y pasan a ser parte del cerebro y no del cráneo.\n",
    "    # Para esto se identifican las regiones conectadas y se eliminan todas menos la más grande.\n",
    "    inverted_mask = ~mask_opened\n",
    "\n",
    "    # Etiquetamos las regiones conectadas\n",
    "    labeled_false, num_false = label(inverted_mask, return_num=True)\n",
    "    if debug:\n",
    "        print(f\"Número de regiones conectadas en la zona False: {num_false}\")\n",
    "\n",
    "    # Si hay más de una región False, mantenemos solo la mayor.\n",
    "    if num_false > 1:\n",
    "        regions = regionprops(labeled_false)\n",
    "        # Seleccionamos la región con mayor área\n",
    "        largest_region = max(regions, key=lambda r: r.area)\n",
    "        largest_label = largest_region.label\n",
    "        if debug:\n",
    "            print(f\"Se han encontrado más de una región False. La región más grande tiene área: {largest_region.area}\")\n",
    "        # Creamos una nueva máscara invertida donde solo se conserva la mayor región False\n",
    "        new_inverted_mask = (labeled_false == largest_label)\n",
    "        # La máscara final se obtiene invirtiendo esta nueva máscara: True es el cerebro y el background\n",
    "        # y False en el resto (cráneo).\n",
    "        mask_opened = ~new_inverted_mask\n",
    "        if debug:\n",
    "            plt.figure(figsize=(12, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.title(\"Inverted mask original\")\n",
    "            plt.imshow(inverted_mask, cmap='gray')\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.title(\"Inverted mask solo mayor región\")\n",
    "            plt.imshow(new_inverted_mask, cmap='gray')\n",
    "            plt.show()\n",
    "    else:\n",
    "        if debug:\n",
    "            print(\"No se detectaron más de dos regiones False. No se aplica corrección.\")\n",
    "    \n",
    "    # Forzar que los 10 píxeles del borde sean False\n",
    "    borde = 6\n",
    "    mask_opened[:, :borde] = False\n",
    "    mask_opened[:, -borde:] = False\n",
    "    \n",
    "    # 3.4 Etiquetar las regiones conectadas en la máscara para eliminar el fondo (ahora se espera que quede solo el cerebro).\n",
    "    labeled, num_labeled = label(mask_opened, return_num=True)\n",
    "    regions = regionprops(labeled)\n",
    "    if debug:\n",
    "        print(f\"Número de regiones conectadas en la zona True: {num_labeled}\")\n",
    "        if len(regions) > 0:\n",
    "            print(\"Regiones encontradas en la zona True:\")\n",
    "            for reg in regions:\n",
    "                print(f\" - Etiqueta: {reg.label}, Área: {reg.area}, BBox: {reg.bbox}\")\n",
    "        else:\n",
    "            print(\"No se encontraron regiones conectadas en la zona True.\")\n",
    "    \n",
    "    if len(regions) == 0:\n",
    "        if debug:\n",
    "            print(\"No se detectó ninguna región. Se retorna la máscara tal como está.\")\n",
    "        final_mask = mask_opened\n",
    "    else:\n",
    "        # Ordenamos las regiones por área de mayor a menor.\n",
    "        sorted_regions = sorted(regions, key=lambda r: r.area, reverse=True)\n",
    "        if debug:\n",
    "            print(\"Se unen las regiones a partir de la segunda:\")\n",
    "            for reg in sorted_regions[1:]:\n",
    "                print(f\" - Etiqueta: {reg.label}, Área: {reg.area}\")\n",
    "        # Inicializamos una máscara vacía (todos False) del mismo tamaño.\n",
    "        final_mask = np.zeros_like(labeled, dtype=bool)\n",
    "        # Unimos (con OR) todas las regiones desde la segunda en adelante.\n",
    "        for region in sorted_regions[1:]:\n",
    "            final_mask |= (labeled == region.label)\n",
    "        if debug:\n",
    "            plt.figure()\n",
    "            plt.title(\"Máscara final (unión de regiones desde la segunda)\")\n",
    "            plt.imshow(final_mask, cmap='gray')\n",
    "            plt.show()\n",
    "            \n",
    "    return final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_masks_to_ct_volume(ct_volume, mask_folder, patient_id, composed_z_map, debug=False):\n",
    "    \"\"\"\n",
    "    Aplica las máscaras almacenadas en mask_folder al volumen ct_volume usando la correspondencia de índices.\n",
    "    \n",
    "    Parámetros:\n",
    "      ct_volume : numpy.ndarray\n",
    "          Volumen CT con forma (t, new_z, x, y), donde new_z es la numeración tras filtrar slices.\n",
    "      mask_folder : str\n",
    "          Carpeta que contiene los archivos de máscara (.npy). Se espera que los archivos se nombren como:\n",
    "          \"case_{patient_id:02d}_{real_z+1:02d}.npy\"\n",
    "      patient_id : int or str\n",
    "          Identificador del paciente.\n",
    "      composed_z_map : dict\n",
    "          Mapeo que relaciona new_z (índice funcional en ct_volume) -> real_z (índice original).\n",
    "      debug : bool\n",
    "          Si es True, se imprime información de depuración y se visualiza el resultado para cada slice.\n",
    "    \n",
    "    Devuelve:\n",
    "      ct_volume : numpy.ndarray\n",
    "          El volumen CT con las máscaras aplicadas en cada slice (para todos los frames temporales).\n",
    "          Los píxeles donde la máscara es False se pondrán a 0.\n",
    "    \"\"\"\n",
    "    # Convertir patient_id a cadena con dos dígitos si es numérico\n",
    "    if isinstance(patient_id, int):\n",
    "        patient_str = f\"{patient_id:02d}\"\n",
    "    else:\n",
    "        patient_str = patient_id\n",
    "\n",
    "    num_new_z = ct_volume.shape[1]\n",
    "    if debug:\n",
    "        print(f\"Aplicando máscaras a {num_new_z} slices (índices funcionales).\")\n",
    "    \n",
    "    for new_z in range(num_new_z):\n",
    "        # Obtener el índice real a partir del mapeo\n",
    "        real_z = composed_z_map.get(new_z, None)\n",
    "        if real_z is None:\n",
    "            if debug:\n",
    "                print(f\"  Advertencia: No se encontró correspondencia para new_z={new_z}. Se omite.\")\n",
    "            continue\n",
    "        \n",
    "        # Construir el nombre del archivo usando el índice real (1-based)\n",
    "        filename = f\"case_{patient_str}_{real_z+1:02d}.npy\"\n",
    "        mask_path = os.path.join(mask_folder, filename)\n",
    "        if not os.path.exists(mask_path):\n",
    "            if debug:\n",
    "                print(f\"  Archivo de máscara no encontrado para new_z={new_z} (real_z={real_z}): {mask_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Cargar la máscara (se espera que sea un array 2D de forma (x, y))\n",
    "        mask = np.load(mask_path)\n",
    "        if debug:\n",
    "            print(f\"Procesando máscara para new_z={new_z} (real_z={real_z}) desde {filename}\")\n",
    "            print(f\"  Forma de la máscara: {mask.shape}, valores únicos: {np.unique(mask)}\")\n",
    "        \n",
    "        # Verificar que la forma de la máscara coincida con la de un slice del CT\n",
    "        if mask.shape != ct_volume.shape[2:]:\n",
    "            if debug:\n",
    "                print(f\"  ERROR: La forma de la máscara {mask.shape} no coincide con la forma del slice {ct_volume.shape[2:]}\")\n",
    "            continue\n",
    "        \n",
    "        # Aplicar la máscara a todos los frames temporales para el slice new_z:\n",
    "        # Donde la máscara es False, se anulan los píxeles.\n",
    "        ct_volume[:, new_z, :, :] *= mask.astype(ct_volume.dtype)\n",
    "        \n",
    "        if debug:\n",
    "            # Mostrar estadísticas del primer frame del slice y visualizarlo.\n",
    "            frame = ct_volume[0, new_z, :, :]\n",
    "            stats = (frame.min(), frame.max(), frame.mean())\n",
    "            print(f\"  Tras aplicar la máscara, primer frame stats (min, max, mean): {stats}\")\n",
    "            \n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(frame, cmap='gray')\n",
    "            plt.title(f\"Masked slice: new_z={new_z} (real_z={real_z})\")\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "    \n",
    "    return ct_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSymmetricRepresentation_4d(ct_volume, debug=True):\n",
    "    \"\"\"\n",
    "    Aplica la representación simétrica a un volumen 4D de CT_4DPWI con dimensiones (t, z, x, y).\n",
    "    \n",
    "    Para cada slice (índice z), se calcula la transformación a partir del frame t=0 y luego se\n",
    "    aplica a todos los frames temporales de ese slice.\n",
    "    \n",
    "    Parámetros:\n",
    "      ct_volume: np.ndarray\n",
    "          Volumen 4D de entrada con forma (t, z, alto, ancho)\n",
    "      debug: bool\n",
    "          Si es True, se muestran imágenes intermedias usando display_debug.\n",
    "    \n",
    "    Retorna:\n",
    "      registered_volume: np.ndarray\n",
    "          Volumen 4D con las imágenes registradas, misma forma que ct_volume.\n",
    "    \"\"\"\n",
    "    # Extraer dimensiones del volumen\n",
    "    t_dim, z_dim, height, width = ct_volume.shape\n",
    "    \n",
    "    # Inicializar el volumen de salida\n",
    "    registered_volume = np.zeros((t_dim, z_dim, height, width))\n",
    "    \n",
    "    # Diccionario para almacenar la transformación de cada slice (calculada a partir de t=0)\n",
    "    transform_maps = {}\n",
    "    \n",
    "    # Para cada slice (z) calculamos la transformación usando el frame t=0\n",
    "    for z in range(z_dim):\n",
    "        ct_slice = ct_volume[0, z, :, :]\n",
    "        if debug:\n",
    "            display_debug(ct_slice, f\"Slice z={z}, frame t=0 original\")\n",
    "        ct_slice_flipped = np.fliplr(ct_slice)\n",
    "        if debug:\n",
    "            display_debug(ct_slice_flipped, f\"Slice z={z}, frame t=0 volteada\")\n",
    "        \n",
    "        fixedImage = sitk.GetImageFromArray(ct_slice)\n",
    "        movingImage = sitk.GetImageFromArray(ct_slice_flipped)\n",
    "    \n",
    "        # Configuramos el registro rígido con Elastix\n",
    "        parameterMap = sitk.GetDefaultParameterMap(\"rigid\")\n",
    "        elastixImageFilter = sitk.ElastixImageFilter()\n",
    "        elastixImageFilter.SetFixedImage(fixedImage)\n",
    "        elastixImageFilter.SetMovingImage(movingImage)\n",
    "        elastixImageFilter.LogToFileOn()\n",
    "        elastixImageFilter.SetParameterMap(parameterMap)\n",
    "        resultImage = elastixImageFilter.Execute()\n",
    "        resultArray = sitk.GetArrayFromImage(resultImage)\n",
    "        if debug:\n",
    "            display_debug(resultArray, f\"Resultado de registro para slice z={z} (frame t=0)\")\n",
    "    \n",
    "        transform_maps[z] = elastixImageFilter.GetTransformParameterMap()\n",
    "    \n",
    "    # Aplicar la transformación calculada para cada slice a todos los frames temporales\n",
    "    for z in range(z_dim):\n",
    "        for t in range(t_dim):\n",
    "            frame = ct_volume[t, z, :, :]\n",
    "            # Opcional: mostrar debug para el primer frame de cada slice\n",
    "            if debug and t == 0:\n",
    "                display_debug(frame, f\"Slice z={z}, frame t={t} original\")\n",
    "            frame_flipped = np.fliplr(frame)\n",
    "            if debug and t == 0:\n",
    "                display_debug(frame_flipped, f\"Slice z={z}, frame t={t} volteado\")\n",
    "    \n",
    "            movingFrame = sitk.GetImageFromArray(frame_flipped)\n",
    "            frameResult = sitk.Transformix(movingFrame, transform_maps[z])\n",
    "            resultFrame = sitk.GetArrayFromImage(frameResult)\n",
    "            if debug and t == 0:\n",
    "                display_debug(resultFrame, f\"Slice z={z}, frame t={t} registrado\")\n",
    "            registered_volume[t, z, :, :] = resultFrame\n",
    "    \n",
    "    return registered_volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing_4d(array):\n",
    "    \"\"\"\n",
    "    Aplica un suavizado temporal a un array 4D de forma (t, z, x, y)\n",
    "    usando una convolución 1D a lo largo del eje temporal.\n",
    "    \n",
    "    El procedimiento es:\n",
    "      1. Reordenar de (t, z, x, y) a (x, y, z, t).\n",
    "      2. Para cada canal (slice, que equivale a z) se aplica conv1d a lo largo del eje temporal.\n",
    "      3. Se reordena la salida a (t_out, z, x, y).\n",
    "    \n",
    "    Parámetros:\n",
    "      array: np.ndarray de forma (t, z, x, y)\n",
    "      \n",
    "    Retorna:\n",
    "      out_rearr: np.ndarray de forma (t_out, z, x, y), donde t_out depende de la convolución.\n",
    "    \"\"\"\n",
    "    # Reordenar de (t, z, x, y) a (x, y, z, t)\n",
    "    array_rearr = np.transpose(array, (2, 3, 1, 0))\n",
    "    h, w, c, t = array_rearr.shape  # aquí h=x, w=y, c=z\n",
    "    \n",
    "    # Definir el kernel (suavizado ponderado)\n",
    "    kernel_np = np.array([0.25, 0.5, 0.25])\n",
    "    kernel_torch = torch.tensor(kernel_np, dtype=torch.float32, device='cuda')\n",
    "    # Reorganizar para conv1d: (out_channels, in_channels, kernel_size) => (1, 1, 3)\n",
    "    kernel_torch = kernel_torch.view(1, 1, -1)\n",
    "    \n",
    "    # Calcular la longitud de la salida real (stride=2, kernel=3, sin padding)\n",
    "    output_len = (t - 3) // 2 + 1\n",
    "    \n",
    "    # Crear el array de salida en la forma (h, w, c, output_len)\n",
    "    out = np.empty((h, w, c, output_len), dtype=np.float32)\n",
    "    \n",
    "    # Para cada canal (slice, es decir, para cada índice en c)\n",
    "    for ch in range(c):\n",
    "        # Extraer la secuencia temporal para ese canal: (h, w, t)\n",
    "        channel = array_rearr[:, :, ch, :]\n",
    "        # Aplanar el plano espacial: (h*w, t)\n",
    "        channel_flat = channel.reshape(-1, t)\n",
    "        # Convertir a tensor en CUDA\n",
    "        channel_torch = torch.tensor(channel_flat, dtype=torch.float32, device='cuda')\n",
    "        # Añadir la dimensión de canal para conv1d: (h*w, 1, t)\n",
    "        channel_torch = channel_torch.unsqueeze(1)\n",
    "        \n",
    "        # Aplicar la convolución 1D a lo largo del eje temporal\n",
    "        result = F.conv1d(channel_torch, kernel_torch, stride=2, padding=0)\n",
    "        # result tiene forma (h*w, 1, output_len)\n",
    "        result_np = result.squeeze(1).cpu().numpy()  # (h*w, output_len)\n",
    "        # Volver a dar forma a (h, w, output_len)\n",
    "        result_np = result_np.reshape(h, w, -1)\n",
    "        out[:, :, ch, :] = result_np\n",
    "        \n",
    "    # Reordenar la salida a la forma (t_out, z, x, y)\n",
    "    out_rearr = np.transpose(out, (3, 2, 0, 1))\n",
    "    return out_rearr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_smoothed_images(ct_volume, symmetric_volume, patient_id, z_map, output_folder):\n",
    "    \"\"\"\n",
    "    Guarda la imagen resultante en el formato deseado.\n",
    "    \n",
    "    Parámetros:\n",
    "      ct_volume: np.ndarray\n",
    "          Volumen preprocesado original con forma (t, z, x, y).\n",
    "      symmetric_volume: np.ndarray\n",
    "          Volumen con la representación simétrica, mismo shape que ct_volume.\n",
    "      patient_id: int o str\n",
    "          Identificador del paciente (se usará en el nombre del archivo).\n",
    "      z_map: dict\n",
    "          Mapeo que relaciona el índice funcional (después de filtrado) con el índice real.\n",
    "      output_folder: str\n",
    "          Ruta de la carpeta donde se guardarán los archivos (p.ej., \"/data/dev/perfu-net/data/train/CTP\").\n",
    "    \n",
    "    El proceso es:\n",
    "      1. Se aplica el suavizado a ambos volúmenes mediante smoothing_4d.\n",
    "      2. Para cada slice (eje z), se crea un array de forma (t_out, 2, x, y),\n",
    "         donde:\n",
    "           - Canal 0: imagen original tras el suavizado.\n",
    "           - Canal 1: imagen simétrica tras el suavizado.\n",
    "      3. Si el slice es completamente negro (todos los valores 0), no se guarda.\n",
    "      4. Se guarda cada slice en un archivo con nombre \"case_{patient_id:02d}_{real_z+1:02d}.npy\".\n",
    "    \"\"\"\n",
    "    # Asegurarse de que la carpeta de salida exista\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Aplicar el suavizado a ambos volúmenes.\n",
    "    # Se supone que smoothing_4d está definida y recibe un array con shape (t, z, x, y),\n",
    "    # devolviendo un array con shape (t_out, z, x, y), donde t_out = (t - 3) // 2 + 1.\n",
    "    smoothed_original = smoothing_4d(ct_volume)\n",
    "    smoothed_symmetric = smoothing_4d(symmetric_volume)\n",
    "    \n",
    "    # Extraer dimensiones (del volumen suavizado)\n",
    "    t_out, z_dim, x, y = smoothed_original.shape\n",
    "    print(f\"Dimensión temporal tras suavizado: {t_out}\")\n",
    "    \n",
    "    for z in range(z_dim):\n",
    "        real_z = z_map[z]  # Índice real (original) para este slice\n",
    "        # Extraer la secuencia temporal para el slice z (forma: (t_out, x, y))\n",
    "        orig_slice = smoothed_original[:, z, :, :]\n",
    "        sym_slice = smoothed_symmetric[:, z, :, :]\n",
    "        \n",
    "        # Crear un array combinado de forma (t_out, 2, x, y)\n",
    "        combined = np.stack([orig_slice, sym_slice], axis=1)\n",
    "        \n",
    "        # Verificar si el slice combinado es completamente negro\n",
    "        if np.all(combined == 0):\n",
    "            print(f\"Slice (real z={real_z}) completamente negro. No se guarda.\")\n",
    "            continue\n",
    "        \n",
    "        # Construir el nombre del archivo usando el índice real (1-based)\n",
    "        filename = f\"case_{int(patient_id):02d}_{real_z+1:02d}.npy\"\n",
    "        filepath = os.path.join(output_folder, filename)\n",
    "        \n",
    "        # Guardar el array\n",
    "        np.save(filepath, combined)\n",
    "        print(f\"Guardado: {filepath}, shape: {combined.shape}\")\n",
    "\n",
    "    return smoothed_original, smoothed_symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_debug_ct4dpwi_nifti(file_path, patient_id, debug):\n",
    "    \"\"\"\n",
    "    Carga un archivo NIfTI de CT_4DPWI con dimensiones (t, z, x, y), aplica el preprocesamiento,\n",
    "    la representación simétrica y el suavizado, y permite depurar interactivamente mostrando:\n",
    "      - Imagen original preprocesada.\n",
    "      - Imagen volteada (np.fliplr).\n",
    "      - Imagen registrada (simétrica).\n",
    "      - Imagen suavizada (resultado de smoothing_4d).\n",
    "    \n",
    "    Se utiliza un mapeo simple para relacionar el índice temporal original con el del suavizado:\n",
    "      smoothed_idx = t_idx // 2\n",
    "    \"\"\"\n",
    "\n",
    "    output_folder = \"/data/dev/perfu-net-1/data/train/CTP\"\n",
    "    \n",
    "    # 1. Cargar la imagen NIfTI y obtener el array 4D\n",
    "    ct_image = sitk.ReadImage(file_path)\n",
    "    ct_volume = sitk.GetArrayFromImage(ct_image)\n",
    "    print(\"Shape original (como lo devuelve sitk):\", ct_volume.shape)\n",
    "    \n",
    "    # Se asume que ct_volume tiene forma (t, z, x, y)\n",
    "    t_dim, z_dim, height, width = ct_volume.shape\n",
    "    \n",
    "    # Verificar y eliminar slices (componentes z) que tengan intensidades entre -25 y 0\n",
    "    valid_z_indices = []\n",
    "    print(\"\\nEvaluando cada slice (componente z):\")\n",
    "    for z in range(z_dim):\n",
    "        # Extraemos todos los frames para este slice z: forma (t, x, y)\n",
    "        slice_data = ct_volume[:, z, :, :]\n",
    "        min_intensity_z = slice_data.min()\n",
    "        max_intensity_z = slice_data.max()\n",
    "        print(f\"  Slice z={z}: Intensidad mínima: {min_intensity_z}, Intensidad máxima: {max_intensity_z}\")\n",
    "        if min_intensity_z >= -25 and max_intensity_z <= 0:\n",
    "            print(f\"    --> Slice z={z} omitido (todos los valores entre -25 y 0)\")\n",
    "        else:\n",
    "            valid_z_indices.append(z)\n",
    "    \n",
    "    if not valid_z_indices:\n",
    "        print(\"No quedan slices válidos (todas las componentes z están entre -25 y 0). Se omite la imagen.\")\n",
    "        return\n",
    "    \n",
    "    # Filtramos ct_volume a solo los slices válidos\n",
    "    ct_volume = ct_volume[:, valid_z_indices, :, :]\n",
    "    # Creamos un mapeo: new_z -> old_z\n",
    "    z_map = { new_z: old_z for new_z, old_z in enumerate(valid_z_indices) }\n",
    "    z_dim = ct_volume.shape[1]  # Actualizar el número de slices\n",
    "\n",
    "    # 2. Preprocesar el volumen 4D (esta función retorna también un mapeo de los slices que quedaron)\n",
    "    ct_volume, preprocessor_z_map = preprocessor_4d(ct_volume, 500, debug=False)\n",
    "    \n",
    "    # Componer el mapeo: \n",
    "    #   preprocessor_z_map mapea: new_z_pp -> índice en el ct_volume antes de preprocessor\n",
    "    #   z_map mapea: índice en el ct_volume inicial -> índice original\n",
    "    # Componemos para que: composed_z_map[new_z_pp] = z_map[ preprocessor_z_map[new_z_pp] ]\n",
    "    composed_z_map = {}\n",
    "    for new_z_pp, intermed_z in enumerate(preprocessor_z_map):\n",
    "        original_z = z_map[intermed_z]\n",
    "        composed_z_map[new_z_pp] = original_z\n",
    "\n",
    "    # Actualizar z_dim según el volumen preprocesado\n",
    "    z_dim = ct_volume.shape[1]\n",
    "    \n",
    "    # 3.1. Generar la máscara de umbral para el cerebro\n",
    "    # Usamos composed_z_map para el naming: la máscara se guardará con el índice original.\n",
    "    output_mask_folder = \"/data/dev/perfu-net-1/data/train/SKULL_MASK\"\n",
    "    os.makedirs(output_mask_folder, exist_ok=True)\n",
    "    for new_z in range(z_dim):\n",
    "        real_z = composed_z_map[new_z]  # Índice original\n",
    "        print(f\"\\nGenerando máscara para slice new_z={new_z} (original z={real_z})\")\n",
    "        # Se extrae el slice correspondiente: se toma el frame t=0 y el slice new_z\n",
    "        slice_2d = ct_volume[0, new_z, :, :]  # (H, W)\n",
    "        # Aquí se llama a la función de umbralado para un slice 2D;\n",
    "        # suponemos que generate_threshold_mask procesa un slice 2D y devuelve la máscara.\n",
    "        skull_mask = generate_threshold_mask(slice_2d, umbral=0.3, debug=False)\n",
    "        \n",
    "        filename = f\"case_{int(patient_id):02d}_{real_z+1:02d}.npy\"\n",
    "        saving_path = os.path.join(output_mask_folder, filename)\n",
    "        np.save(saving_path, skull_mask)\n",
    "        if debug:\n",
    "            print(f\"Guardada máscara en: {saving_path}\")\n",
    "            \n",
    "    ct_volume = apply_masks_to_ct_volume(ct_volume, output_mask_folder, patient_id, composed_z_map, debug=debug)\n",
    "\n",
    "    # 3. Calcular la representación simétrica\n",
    "    symmetric_volume = getSymmetricRepresentation_4d(ct_volume, debug=debug)\n",
    "    \n",
    "    # 5. Guardar imágenes suavizadas, pasando el mapeo compuesto para que los nombres usen el índice original.\n",
    "    ct_volume_smoothed, symmetric_volume_smoothed = save_smoothed_images(ct_volume, symmetric_volume, patient_id, composed_z_map, output_folder)\n",
    "\n",
    "    \n",
    "    def show_frame(t_idx, z_idx):\n",
    "        \"\"\"\n",
    "        Para un frame temporal t_idx y slice z_idx, muestra:\n",
    "          - La imagen original preprocesada.\n",
    "          - La imagen volteada (np.fliplr).\n",
    "          - La imagen registrada (simétrica).\n",
    "          - La imagen suavizada (resultado de smoothing_4d).\n",
    "        \n",
    "        Se mapea el índice t_idx al del suavizado usando:\n",
    "          smoothed_idx = t_idx // 2\n",
    "        \"\"\"\n",
    "        original = ct_volume[t_idx, z_idx, :, :]\n",
    "        flipped = np.fliplr(original)\n",
    "        registered = symmetric_volume[t_idx, z_idx, :, :]\n",
    "        smoothed_idx = t_idx // 2  # Mapeo simple para relacionar ambos tiempos.\n",
    "        t_smoothed = ct_volume_smoothed.shape[0]\n",
    "        # Asegurarse de que el índice no exceda el rango del volumen suavizado:\n",
    "        if smoothed_idx >= t_smoothed:\n",
    "            smoothed_idx = t_smoothed - 1\n",
    "        smoothed = symmetric_volume_smoothed[smoothed_idx, z_idx, :, :]\n",
    "        \n",
    "        # Mostrar en 4 subplots (2 filas x 2 columnas)\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        axs = axs.flatten()\n",
    "        \n",
    "        axs[0].imshow(original, cmap='gray')\n",
    "        axs[0].set_title(f\"t={t_idx}, z={z_idx} original\")\n",
    "        axs[0].axis('off')\n",
    "        \n",
    "        axs[1].imshow(flipped, cmap='gray')\n",
    "        axs[1].set_title(f\"t={t_idx}, z={z_idx} volteado\")\n",
    "        axs[1].axis('off')\n",
    "        \n",
    "        axs[2].imshow(registered, cmap='gray')\n",
    "        axs[2].set_title(f\"t={t_idx}, z={z_idx} registrado\")\n",
    "        axs[2].axis('off')\n",
    "        \n",
    "        axs[3].imshow(smoothed, cmap='gray')\n",
    "        axs[3].set_title(f\"smoothed (t={smoothed_idx}, z={z_idx})\")\n",
    "        axs[3].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # 5. Crear sliders interactivos para elegir el frame (t) y el slice (z)\n",
    "    interact(show_frame,\n",
    "             t_idx=IntSlider(min=0, max=t_dim-1, step=1, value=0, description=\"Tiempo (t)\"),\n",
    "             z_idx=IntSlider(min=0, max=z_dim-1, step=1, value=0, description=\"Slice (z)\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta raíz donde se encuentran los casos de TRAINING\n",
    "training_path = '/data/ISLES-2018/TRAINING'\n",
    "# Ruta de la carpeta donde se almacenan los pacientes ya procesados\n",
    "output_dir = '/data/dev/perfu-net-1/data/train/CTP'\n",
    "\n",
    "# Iterar sobre cada carpeta de paciente (se asume el patrón \"case_XX\")\n",
    "for case_folder in glob(os.path.join(training_path, 'case_*')):\n",
    "    # Extraer el id del paciente (por ejemplo, \"12\" de \"case_12\")\n",
    "    # Asegurarse de que el patient_id tenga dos dígitos (añadir 0 a la izquierda si es necesario)\n",
    "    patient_id = case_folder.split(os.sep)[-1].split('_')[1]\n",
    "    if len(patient_id) == 1:\n",
    "        patient_id = \"0\" + patient_id\n",
    "    \n",
    "    # Verificar si este paciente ya fue procesado.\n",
    "    # Se busca cualquier archivo cuyo nombre contenga \"case_{patient_id}\" en output_dir.\n",
    "    processed_files = glob(os.path.join(output_dir, f\"case_{patient_id}_*.npy\"))\n",
    "    if processed_files:\n",
    "        print(f\"Paciente {patient_id} ya procesado. Saltando.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Procesando paciente {patient_id} en {case_folder}\")\n",
    "    \n",
    "    # Buscar de forma recursiva archivos .nii dentro de cada carpeta del caso\n",
    "    nii_files = glob(os.path.join(case_folder, '**', '*.nii'), recursive=True)\n",
    "    for file_path in nii_files:\n",
    "        # Sólo procesar los archivos que contengan \"CT_4DPWI\" en su ruta/nombre\n",
    "        if 'CT_4DPWI' in file_path:\n",
    "            print(f\"  Procesando archivo: {file_path}\")\n",
    "            # Se llama a la función interactiva, pasando file_path, patient_id y debug=False\n",
    "            interactive_debug_ct4dpwi_nifti(file_path, patient_id, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
