{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import torch\n",
    "import nibabel as nib\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from skimage.exposure import equalize_hist\n",
    "from einops.einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def getSymmetricRepresentation(ct_volume):\n",
    "    # the volume is either h x w x t or h x w x modalities with the first modality the NCCT\n",
    "    ct_slice = ct_volume[0]\n",
    "    ct_slice_flipped = np.fliplr(ct_slice)\n",
    "    fixedImage = sitk.GetImageFromArray(ct_slice)\n",
    "    movingImage = sitk.GetImageFromArray(ct_slice_flipped)\n",
    "\n",
    "    # Elastix part, determine rotation\n",
    "    parameterMap = sitk.GetDefaultParameterMap(\"rigid\")\n",
    "    parameterMap['DefaultPixelValue'] = ['-0.5']\n",
    "    parameterMap[\"AutomaticParameterEstimation\"] = [\"false\"]\n",
    "    parameterMap[\"ResampleInterpolator\"] = [\"FinalNearestNeighborInterpolator\"]\n",
    "    elastixImageFilter = sitk.ElastixImageFilter()\n",
    "    elastixImageFilter.SetFixedImage(fixedImage)\n",
    "    elastixImageFilter.SetMovingImage(movingImage)\n",
    "    elastixImageFilter.LogToFileOn()\n",
    "    elastixImageFilter.SetParameterMap(parameterMap)\n",
    "    resultImage = elastixImageFilter.Execute()\n",
    "\n",
    "    # We now determined the transformation of the flipped scan to the original,\n",
    "    # either for the first frame or for the first modality\n",
    "    # Now we apply the same transformation to the other modalities or the other frames\n",
    "\n",
    "    empty = np.zeros((ct_volume.shape[0],256,256))\n",
    "    for frame_nr in range(ct_volume.shape[0]):\n",
    "        frame = ct_volume[frame_nr,:,:]\n",
    "        frame_flipped = np.fliplr(frame)\n",
    "        movingFrame = sitk.GetImageFromArray(frame_flipped)\n",
    "        frameResult = sitk.Transformix(movingFrame, elastixImageFilter.GetTransformParameterMap())\n",
    "        empty[frame_nr,:,:] = sitk.GetArrayFromImage(frameResult)\n",
    "    return empty\n",
    "\n",
    "def getSym(volume):\n",
    "    empty = np.zeros((volume.shape[0],256,256,2))\n",
    "    sym_frame = getSymmetricRepresentation(volume)\n",
    "    print(sym_frame.shape)\n",
    "    empty[...,0] = volume\n",
    "    empty[...,1] = sym_frame\n",
    "    return empty\n",
    "\n",
    "def preprocessor(nifti, clip_value): #3D nifti\n",
    "    # Clip entire 4D volume\n",
    "    nifti = np.clip(nifti, 0, clip_value)\n",
    "    # Equalize entire histogram\n",
    "    nifti = equalize_hist(nifti, nbins=20000, mask=(nifti > 0))\n",
    "    nifti = nifti - np.min(nifti)\n",
    "    # Shift distribution, not the zeroes\n",
    "    mask=(nifti > 0)\n",
    "    mdata = np.ma.masked_array(nifti, mask=~mask.astype(bool))\n",
    "    mdata =(mdata - 0.5)\n",
    "    mdata.mask = np.ma.nomask\n",
    "    return mdata\n",
    "\n",
    "def smoothing(array):\n",
    "    # array: (h, w, 2, t)\n",
    "    h, w, c, t = array.shape\n",
    "    kernel_np = np.array([0.25, 0.5, 0.25])\n",
    "    kernel_torch = torch.tensor(kernel_np, dtype=torch.float32).to('cuda')\n",
    "    # Queremos un kernel de forma (out_channels, in_channels, kernel_size) => (1, 1, 3)\n",
    "    kernel_torch = kernel_torch.view(1, 1, -1)\n",
    "    \n",
    "    # Calcular longitud de la salida real\n",
    "    t = array.shape[-1]\n",
    "    output_len = (t - 3) // 2 + 1  # stride=2, kernel=3, padding=0\n",
    "    \n",
    "    # Crear el array de salida con el tamaño esperado\n",
    "    out = np.empty([256, 256, 2, output_len], dtype=np.float32)\n",
    "    \n",
    "    # Para cada canal, aplanamos (h, w) en una dimensión N\n",
    "    # channel i: (h, w, t) => reshape => (h*w, 1, t)\n",
    "    for ch in range(c):\n",
    "        channel = array[:,:,ch,:]  # (h, w, t)\n",
    "        channel_flat = channel.reshape(-1, t)  # (h*w, t)\n",
    "        channel_torch = torch.tensor(channel_flat, dtype=torch.float32, device='cuda')\n",
    "        \n",
    "        # Añadimos dimensión para conv1d: (N, 1, t)\n",
    "        channel_torch = channel_torch.unsqueeze(1)  # -> (h*w, 1, t)\n",
    "        \n",
    "        # Aplicamos la conv1d a TODAS las secuencias a la vez\n",
    "        result = F.conv1d(channel_torch, kernel_torch, stride=2, padding=0)\n",
    "        # result es (h*w, 1, t//2)\n",
    "\n",
    "        result_np = result.squeeze(1).cpu().numpy()  # (h*w, t//2)\n",
    "        # Lo llevamos a (h, w, t//2)\n",
    "        result_np = result_np.reshape(h, w, -1)\n",
    "        \n",
    "        # Asignamos en la salida\n",
    "        out[:,:,ch,:] = result_np\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def write_np(array, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        np.save(f, array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def datamaker(case = 8, dataset='TRAINING'):\n",
    "    path = os.path.join('/data/ISLES-2018/',dataset)\n",
    "    for file in glob.glob(os.path.join(path,f'case_{case}','*/*.nii')):\n",
    "        if 'CT_MTT' in file:\n",
    "            CT_MTT = sitk.GetArrayFromImage(sitk.ReadImage(file))\n",
    "            CT_MTT = rearrange(CT_MTT, 'd h (w c) -> c h w d', c=1)\n",
    "        if 'CT_Tmax' in file:\n",
    "            CT_Tmax = sitk.GetArrayFromImage(sitk.ReadImage(file))\n",
    "            CT_Tmax = rearrange(CT_Tmax, 'd h (w c) -> c h w d', c=1)\n",
    "        if 'CT_CBF' in file:\n",
    "            CT_CBF = sitk.GetArrayFromImage(sitk.ReadImage(file))\n",
    "            CT_CBF = rearrange(CT_CBF, 'd h (w c) -> c h w d', c=1)\n",
    "        if 'CT_CBV' in file:\n",
    "            CT_CBV = sitk.GetArrayFromImage(sitk.ReadImage(file))\n",
    "            CT_CBV = rearrange(CT_CBV, 'd h (w c) -> c h w d', c=1)\n",
    "        if 'OT' in file and dataset=='TRAINING':\n",
    "            CT_MASK = sitk.GetArrayFromImage(sitk.ReadImage(file))\n",
    "            CT_MASK = rearrange(CT_MASK, 'd h w -> h w d')\n",
    "        if 'CT_4DPWI' in file:\n",
    "            CT_4DPWI = sitk.GetArrayFromImage(sitk.ReadImage(file))\n",
    "            CT_4DPWI = rearrange(CT_4DPWI, ' t d h w -> t h w d')\n",
    "        if '.CT.' in file:\n",
    "            CT = sitk.GetArrayFromImage(sitk.ReadImage(file))\n",
    "            CT = rearrange(CT, 'd h (w c) -> c h w d', c=1)\n",
    "    print('Data case %i loaded'%(case))\n",
    "    folder = 'train' if dataset == 'TRAINING' else 'test'\n",
    "    os.makedirs(os.path.join(os.getcwd(), folder, 'COMPLETE_MASK'), exist_ok=True)\n",
    "    maskpath = [file for file in glob.glob(os.path.join(path,f'case_{case}','*/*.nii')) if 'OT' in file][0]\n",
    "    savename = os.path.join(os.getcwd(), folder, 'COMPLETE_MASK', 'case_{}.nii'.format(str(case).zfill(2)))\n",
    "    shutil.copy(maskpath,savename)\n",
    "    # create brainmask\n",
    "    CT_SKULL = CT\n",
    "    skull = CT_CBV + CT_MTT + CT_Tmax + CT_CBF\n",
    "    skull = (skull>0)\n",
    "\n",
    "    CT = np.multiply(skull,CT)\n",
    "    # create CTP without skull\n",
    "    skull_frames = np.zeros(CT_4DPWI.shape)\n",
    "    for i in range(CT_4DPWI.shape[0]):\n",
    "        skull_frames[0,...] = skull[0,...]\n",
    "    # we generate the data per slice\n",
    "    for _z in range(CT.shape[-1]):\n",
    "        print(f\"Processing slice {_z+1} of {CT.shape[-1]}\")\n",
    "        # # We only use slices with infarcts fro training\n",
    "        # if np.max(CT_MASK[:,:,_z]) != 1.0 and dataset=='TRAINING':\n",
    "        #     print('Slice without infarct found, continuing')\n",
    "        #     continue\n",
    "\n",
    "        baseline = preprocessor(CT[:,:,:,_z], 500)\n",
    "        mtt = preprocessor(CT_MTT[:,:,:,_z], 500)\n",
    "        tmax = preprocessor(CT_Tmax[:,:,:,_z], 500)\n",
    "        cbf = preprocessor(CT_CBF[:,:,:,_z], 500)\n",
    "        cbv = preprocessor(CT_CBV[:,:,:,_z], 500)\n",
    "        ct_with_skull = preprocessor(CT_SKULL[:,:,:,_z], 500)\n",
    "        ct_modalities = np.concatenate([baseline, mtt, tmax, cbf, cbv,ct_with_skull], axis=0)\n",
    "\n",
    "        ct_modalities_sym = getSym(ct_modalities)\n",
    "\n",
    "        ct_modalities_sym =  rearrange(ct_modalities_sym, 'mods h w c -> mods c h w')\n",
    "\n",
    "\n",
    "        folder = 'train' if dataset == 'TRAINING' else 'test'\n",
    "        os.makedirs(os.path.join(os.getcwd(), folder, 'CT'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(os.getcwd(), folder, 'CTP_CBF'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(os.getcwd(), folder, 'CTP_CBV'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(os.getcwd(), folder, 'CTP_MTT'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(os.getcwd(), folder, 'CTP_Tmax'), exist_ok=True)\n",
    "        write_np(ct_modalities_sym[0], os.path.join(os.getcwd(), folder, 'CT', 'case_%s_%s.npy' % (str(case).zfill(2), str(_z+1).zfill(2))))\n",
    "        write_np(ct_modalities_sym[1], os.path.join(os.getcwd(), folder, 'CTP_MTT', 'case_%s_%s.npy'%(str(case).zfill(2),str(_z+1).zfill(2))))\n",
    "        write_np(ct_modalities_sym[2], os.path.join(os.getcwd(), folder, 'CTP_Tmax', 'case_%s_%s.npy'%(str(case).zfill(2),str(_z+1).zfill(2))))\n",
    "        write_np(ct_modalities_sym[3], os.path.join(os.getcwd(), folder, 'CTP_CBF', 'case_%s_%s.npy'%(str(case).zfill(2),str(_z+1).zfill(2))))\n",
    "        write_np(ct_modalities_sym[4], os.path.join(os.getcwd(), folder, 'CTP_CBV', 'case_%s_%s.npy'%(str(case).zfill(2),str(_z+1).zfill(2))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "datamaker(case=93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(95):\n",
    "    datamaker(case=i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar para eliminar los casos que no se utilizan en la ejecución con y sin lesión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def process_folder(folder_path, mask_set):\n",
    "    \"\"\"\n",
    "    Procesa una carpeta dada:\n",
    "    - Lista los archivos que cumplen con el patrón 'case_*.npy'.\n",
    "    - Compara con los archivos de la carpeta MASK (mask_set).\n",
    "    - Imprime los archivos presentes y aquellos que no están en MASK.\n",
    "    - Elimina los archivos que no se encuentren en MASK.\n",
    "    \"\"\"\n",
    "    # Obtener lista de archivos en la carpeta actual\n",
    "    files = sorted([os.path.basename(f) for f in glob.glob(os.path.join(folder_path, \"case_*.npy\"))])\n",
    "    \n",
    "    print(f\"\\nArchivos en {os.path.basename(folder_path)}:\")\n",
    "    for f in files:\n",
    "        print(f)\n",
    "    \n",
    "    # Comparar archivos de la carpeta con los de MASK\n",
    "    files_set = set(files)\n",
    "    files_not_in_mask = sorted(files_set - mask_set)\n",
    "    \n",
    "    if files_not_in_mask:\n",
    "        print(f\"\\nArchivos en {os.path.basename(folder_path)} que NO están en MASK:\")\n",
    "        for f in files_not_in_mask:\n",
    "            print(f)\n",
    "        \n",
    "        # Eliminar los archivos que no están en MASK\n",
    "        for filename in files_not_in_mask:\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                os.remove(filepath)\n",
    "                print(f\"Eliminado: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error al eliminar {filename}: {e}\")\n",
    "    else:\n",
    "        print(f\"Todos los archivos en {os.path.basename(folder_path)} están presentes en MASK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "base_path = \"/data/dev/perfu-net-1/data/train\"\n",
    "mask_folder = os.path.join(base_path, \"MASK\")\n",
    "    \n",
    "# Lista de carpetas a procesar\n",
    "folders = [\"CT\", \"CTP_CBF\", \"CTP_CBV\", \"CTP_MTT\", \"CTP_Tmax\", \"MASK\"]\n",
    "    \n",
    "# Obtener el set de archivos de MASK\n",
    "mask_files = sorted([os.path.basename(f) for f in glob.glob(os.path.join(mask_folder, \"case_*.npy\"))])\n",
    "mask_set = set(mask_files)\n",
    "    \n",
    "print(\"Archivos en MASK:\")\n",
    "for f in mask_files:\n",
    "    print(f)\n",
    "    \n",
    "# Procesar cada carpeta de forma iterativa\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    print(\"\\n-------------------------------------------\")\n",
    "    process_folder(folder_path, mask_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de querer eliminar todos los casos donde no existe núcleo isquémico se debe ejecutar el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Iterar sobre cada archivo en MASK\n",
    "for mask_path in mask_files:\n",
    "    # Cargar el array de la máscara\n",
    "    mask_path = os.path.join(mask_folder, mask_path)\n",
    "    mask = np.load(mask_path)\n",
    "    \n",
    "    # Verificar si todos los píxeles son False\n",
    "    if not mask.any():\n",
    "        filename = os.path.basename(mask_path)\n",
    "        print(f\"Eliminando caso {filename} ya que todos los píxeles son False en MASK.\")\n",
    "        \n",
    "        # Recorrer todas las carpetas y eliminar el archivo correspondiente si existe\n",
    "        for folder in folders:\n",
    "            file_path = os.path.join(base_path, folder, filename)\n",
    "            if os.path.exists(file_path):\n",
    "                try:\n",
    "                    os.remove(file_path)\n",
    "                    print(f\"  Eliminado: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error al eliminar {file_path}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
