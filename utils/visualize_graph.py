# from graphviz import Digraph
# import torch
# from torch.autograd import Variable
# from torch.nn.modules.module import _addindent
# import numpy as np
#
#
# def make_dot(var, params=None):
#     """ Produces Graphviz representation of PyTorch autograd graph
#     Blue nodes are the Variables that require grad, orange are Tensors
#     saved for backward in torch.autograd.Function
#     Args:
#         var: output Variable
#         params: dict of (name, Variable) to add names to node that
#             require grad (TODO: make optional)
#     """
#     if params is not None:
#         assert isinstance(params.values()[0], Variable)
#         param_map = {id(v): k for k, v in params.items()}
#
#     node_attr = dict(style='filled',
#                      shape='box',
#                      align='left',
#                      fontsize='12',
#                      ranksep='0.1',
#                      height='0.2')
#     dot = Digraph(node_attr=node_attr, graph_attr=dict(size="12,12"))
#     seen = set()
#
#     def size_to_str(size):
#         return '(' + (', ').join(['%d' % v for v in size]) + ')'
#
#     def add_nodes(var):
#         if var not in seen:
#             if torch.is_tensor(var):
#                 dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')
#             elif hasattr(var, 'variable'):
#                 u = var.variable
#                 name = param_map[id(u)] if params is not None else ''
#                 node_name = '%s\n %s' % (name, size_to_str(u.size()))
#                 dot.node(str(id(var)), node_name, fillcolor='lightblue')
#             else:
#                 dot.node(str(id(var)), str(type(var).__name__))
#             seen.add(var)
#             if hasattr(var, 'next_functions'):
#                 for u in var.next_functions:
#                     if u[0] is not None:
#                         dot.edge(str(id(u[0])), str(id(var)))
#                         add_nodes(u[0])
#             if hasattr(var, 'saved_tensors'):
#                 for t in var.saved_tensors:
#                     dot.edge(str(id(t)), str(id(var)))
#                     add_nodes(t)
#
#     add_nodes(var.grad_fn)
#     return dot
#
#
# def torch_summarize(model, show_weights=True, show_parameters=True):
#     """Summarizes torch model by showing trainable parameters and weights."""
#     tmpstr = model.__class__.__name__ + ' (\n'
#     for key, module in model._modules.items():
#         # if it contains layers let call it recursively to get params and weights
#         if type(module) in [
#             torch.nn.modules.container.Container,
#             torch.nn.modules.container.Sequential
#         ]:
#             modstr = torch_summarize(module)
#         else:
#             modstr = module.__repr__()
#         modstr = _addindent(modstr, 2)
#
#         params = sum([np.prod(p.size()) for p in module.parameters()])
#         weights = tuple([tuple(p.size()) for p in module.parameters()])
#
#         tmpstr += '  (' + key + '): ' + modstr
#         if show_weights:
#             tmpstr += ', weights={}'.format(weights)
#         if show_parameters:
#             tmpstr += ', parameters={}'.format(params)
#         tmpstr += '\n'
#
#     tmpstr = tmpstr + ')'
#     return tmpstr
#
# # TODO USE https://github.com/szagoruyko/pytorchviz